{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prathamesh 2017-04-02\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "% watermark -a Prathamesh -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Learning about gRPC and querying from gRPC server (tfserving)\n",
    "\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[gRPC](http://www.grpc.io/about/) about page describes it as:\n",
    "\n",
    "> gRPC is a modern open source high performance RPC framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking and authentication. It is also applicable in last mile of distributed computing to connect devices, mobile applications and browsers to backend services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I started off with REST and to be frank it is easy to wrap your head around the concept of RESTful APIs. You have end points that you can understand, you make a request and query the shit out of the source with JSON requests/responses switching hands. End of story, everyone's happy.\n",
    "\n",
    "When I learnt about gRPC while reading about TensorFlow serving (tfserving), I thought okay...some Google level thing that I won't be bothered with. I was naive, and stupid. The tfserver was up and running, I was happy...the happiness was short lived though.\n",
    "\n",
    "How to query the server, REST wasn't an option. Though there are work arounds to REST it, but getting out of comfort zone seems to be a good option. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### gRPC in a nutshell\n",
    "\n",
    "- HTTP2 wrapped Remote Procedure Call (RPC) protocol where high level service definitions describe the API using Protocol Buffers (protobuf).\n",
    "\n",
    "(__NOTE:__ _What is protobuf? _ )\n",
    "\n",
    "- Client and server code generated from the service definition in 10+ languages. \n",
    "- Multiple connection types: __Unary, Server-side streaming, client side streaming and bi-directional streaming__\n",
    "- Multiple authentication option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We already have the gRPC Server running in C++ on our Google Compute Engine instance. We just need to create a gRPC client in Python (since, our main stack includes Python). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To create a client, we need to follow a few steps (_Source from this talk @28:07 -> [Introduction to gRPC](https://www.youtube.com/watch?v=kUz2zjkKxFg)_):\n",
    "\n",
    "1. Create managed channel for the connection.\n",
    "2. Create a blocking or non-blocking client stub with the channel.\n",
    "3. Create a request.\n",
    "4. Send the request using the stub.\n",
    "5. Handle the responses in sync or async mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Installing python gRPC and related modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grpcio\n",
      "  Downloading grpcio-1.2.1-cp35-cp35m-manylinux1_x86_64.whl (5.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.1MB 111kB/s ta 0:00:011    97% |███████████████████████████████ | 5.0MB 425kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.2.0 in /home/pratos/miniconda3/envs/nasscom/lib/python3.5/site-packages (from grpcio)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/pratos/miniconda3/envs/nasscom/lib/python3.5/site-packages (from grpcio)\n",
      "Collecting enum34>=1.0.4 (from grpcio)\n",
      "  Using cached enum34-1.1.6-py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /home/pratos/miniconda3/envs/nasscom/lib/python3.5/site-packages/setuptools-27.2.0-py3.5.egg (from protobuf>=3.2.0->grpcio)\n",
      "Installing collected packages: enum34, grpcio\n",
      "Successfully installed enum34-1.1.6 grpcio-1.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install grpcio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import grpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pratos/Side-Project/learning-tensorflow\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'predict_pb2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d5008e4784a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mserving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_serving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mservingtensorflow_serving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprediction_service_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'predict_pb2'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from serving.tensorflow_serving.apis import predict_pb2\n",
    "from servingtensorflow_serving.apis import prediction_service_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_string('server', '104.197.123.248:9000',\n",
    "                           'PredictionService host:port')\n",
    "tf.app.flags.DEFINE_string('image', '', 'path to image in JPEG format')\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
